# CMB: ä¸­æ–‡ç»¼åˆåŒ»å­¦åŸºå‡†
![CMB](assets/title.png)
<p align="center">
   ğŸ“ƒ <a href="https://arxiv.org/abs/2308.08833" target="_blank">Paper</a> â€¢ ğŸŒ <a href="https://cmedbenchmark.llmzoo.com/#home" target="_blank">Website</a> â€¢ ğŸ¤— <a href="https://huggingface.co/datasets/FreedomIntelligence/CMB" target="_blank">HuggingFace</a>  
   <br>  <a href="https://github.com/FreedomIntelligence/CMB/blob/main/README_zh.md">   ä¸­æ–‡</a> | <a href="https://github.com/FreedomIntelligence/CMB/blob/main/README.md"> English
</p>

## ğŸŒˆ æ›´æ–°
* **[2024.03.14]** CMBè¢«**2024 NAACL**ä¼šè®®å½•ç”¨ï¼Œæ„Ÿè°¢å­¦æœ¯ç•Œçš„è®¤å¯
* **[2024.02.21]** CMBæµ‹è¯•ç­”æ¡ˆå·²æ›´æ–°ï¼Œå¹¶ä¿®å¤äº†ä¸€äº›å› ç‰ˆæœ¬ç®¡ç†ç–æ¼å¯¼è‡´çš„é”™è¯¯
* **[2024.01.08]** ä¸ºäº†æ–¹ä¾¿æµ‹è¯•ï¼Œæˆ‘ä»¬å…¬å¼€äº†CMB-Examçš„[ç­”æ¡ˆ](https://github.com/FreedomIntelligence/CMB/tree/main/data)
* **[2023.09.22]** CMBè¢«æ”¶å½•äº[OpenCompass](https://github.com/open-compass/opencompass)ä¸­
* **[2023.08.01]** ğŸ‰ğŸ‰ğŸ‰ CMBå…¬å¼€ï¼ğŸ‰ğŸ‰ğŸ‰
* **[2023.08.21]** [è®ºæ–‡](https://arxiv.org/abs/2308.08833)å‘è¡¨



## ğŸŒ ä¸‹è½½

- (æ¨è)ä¸‹è½½[zipæ–‡ä»¶](https://github.com/FreedomIntelligence/CMB/tree/main/data):
    ```bash
    git clone "https://github.com/FreedomIntelligence/CMB.git" && cd CMB && unzip "./data/CMB.zip" -d "./data/" && rm "./data/CMB.zip"
    ```
- ä»[HuggingFace datasets](https://huggingface.co/datasets/FreedomIntelligence/CMB)ä¸‹è½½æ•°æ®:
  ```python
  from datasets import load_dataset
  # CMB-Exam datasets ï¼ˆmultiple-choice and multiple-answer questionsï¼‰
  exam_datasets = load_dataset('FreedomIntelligence/CMB','exam')
  # CMB-Clin datasets
  clin_datasets = load_dataset('FreedomIntelligence/CMB','clin')
  ```
- ä»[ç™¾åº¦äº‘](https://pan.baidu.com/s/1Uv7PgU1gOXrD3PYhG8_opQ?pwd=j0np)ä¸‹è½½æ•°æ®





## ğŸ¥‡ æ’è¡Œæ¦œ 

è¯·å‚è§å®˜ç½‘[Leaderboard](https://cmedbenchmark.llmzoo.com/static/leaderboard.html).



## ğŸ¥¸ æ•°æ®é›†ä»‹ç»
![CMB](assets/CMB-2.svg)
### ç»„æˆéƒ¨åˆ†
- CMB-Exam: å…¨æ–¹ä½å¤šå±‚æ¬¡æµ‹è¯„æ¨¡å‹åŒ»ç–—çŸ¥è¯†;
   - ç»“æ„: 6å¤§é¡¹28å°é¡¹ï¼Œè¯¦è§ä¸Šå›¾CMB-Exam, [ç›®å½•åœ°å€](catalog.md);
   - CMB-test: 11200é“é¢˜ç›®ï¼Œæ¯ä¸€å°é¡¹400é“é¢˜ç›®; 
   - CMB-val: 280é“é™„å¸¦è¯¦ç»†è§£æçš„é¢˜ç›®; Few Shotæ•°æ®é›†;
   - CMB-train: 269359é“é¢˜ç›®; æ¨¡å‹åŒ»ç–—çŸ¥è¯†æ³¨å…¥;
   
- CMB-Clin: æµ‹è¯„å¤æ‚ä¸´åºŠé—®è¯Šèƒ½åŠ›
   - æ•°æ®: 74ä¾‹å¤æ‚ç—…ä¾‹é—®è¯Š; 


### CMB-Exam Item 
```json
{
    "exam_type": "åŒ»å¸ˆè€ƒè¯•",
    "exam_class": "æ‰§ä¸šåŒ»å¸ˆ",
    "exam_subject": "å£è…”æ‰§ä¸šåŒ»å¸ˆ",
    "question": "æ‚£è€…ï¼Œç”·æ€§ï¼Œ11å²ã€‚è¿‘2ä¸ªæœˆæ¥æ—¶æœ‰ä½çƒ­ï¼ˆ37ï½38â„ƒï¼‰ï¼Œå…¨èº«æ— æ˜æ˜¾ç—‡çŠ¶ã€‚æŸ¥ä½“æ— æ˜æ˜¾é˜³æ€§ä½“å¾ã€‚Xçº¿æ£€æŸ¥å‘ç°å³è‚ºä¸­éƒ¨æœ‰ä¸€ç›´å¾„çº¦0.8cmç±»åœ†å½¢ç—…ç¶ï¼Œè¾¹ç¼˜ç¨æ¨¡ç³Šï¼Œè‚ºé—¨æ·‹å·´ç»“è‚¿å¤§ã€‚æ­¤ç”·å­©å¯èƒ½æ‚£",
    "answer": "D",
    "question_type": "å•é¡¹é€‰æ‹©é¢˜",
    "option": {
        "A": "å°å¶å‹è‚ºç‚",
        "B": "æµ¸æ¶¦æ€§è‚ºç»“æ ¸",
        "C": "ç»§å‘æ€§è‚ºç»“æ ¸",
        "D": "åŸå‘æ€§è‚ºç»“æ ¸",
        "E": "ç²Ÿç²’å‹è‚ºç»“æ ¸"
    }
},
```
- exam_type: å¤§é¡¹åˆ†ç±»; 
- exam_class: å°é¡¹åˆ†ç±»; 
- exam_subject: å…·ä½“ç§‘å®¤æˆ–ç»†åˆ†å­¦ç§‘åˆ†ç±»; 
- question_type: åªæœ‰"å•é¡¹é€‰æ‹©é¢˜"å’Œ"å¤šé¡¹é€‰æ‹©é¢˜";

### CMB-Clin Item 
```json
{
    "id": "0",
    "title": "æ¡ˆä¾‹åˆ†æ-è…¹å¤–ç–",
    "description": "ç°ç—…å²\nï¼ˆ1ï¼‰ç—…å²æ‘˜è¦\n     ç—…äººï¼Œç”·ï¼Œ49å²ï¼Œ3å°æ—¶å‰è§£å¤§ä¾¿åå‡ºç°å³ä¸‹è…¹ç–¼ç—›ï¼Œå³ä¸‹è…¹å¯è§¦åŠä¸€åŒ…å—ï¼Œæ—¢å¾€ä½“å¥ã€‚\nï¼ˆ2ï¼‰ä¸»è¯‰\n     å³ä¸‹è…¹ç—›å¹¶è‡ªæ‰ªåŠåŒ…å—3å°æ—¶ã€‚\n\nä½“æ ¼æ£€æŸ¥\nä½“æ¸©ï¼š T 37.8â„ƒï¼ŒP 101æ¬¡ï¼åˆ†ï¼Œå‘¼å¸22æ¬¡/åˆ†ï¼ŒBP 100/60mmHgï¼Œè…¹è½¯ï¼Œæœªè§èƒƒè‚ å‹è •åŠ¨æ³¢ï¼Œè‚è„¾è‚‹ä¸‹æœªåŠï¼Œäºå³ä¾§è…¹è‚¡æ²ŸåŒºå¯æ‰ªåŠä¸€åœ†å½¢è‚¿å—ï¼Œçº¦4cmÃ—4cmå¤§å°ï¼Œæœ‰å‹ç—›ã€ç•Œæ¬ æ¸…ï¼Œä¸”è‚¿å—ä½äºè…¹è‚¡æ²ŸéŸ§å¸¦ä¸Šå†…æ–¹ã€‚\n\nè¾…åŠ©æ£€æŸ¥\nï¼ˆ1ï¼‰å®éªŒå®¤æ£€æŸ¥\n     è¡€å¸¸è§„ï¼šWBC 5.0Ã—109ï¼Lï¼ŒN 78ï¼…ã€‚\n     å°¿å¸¸è§„æ­£å¸¸ã€‚\nï¼ˆ2ï¼‰å¤šæ™®å‹’è¶…å£°æ£€æŸ¥\n     æ²¿è…¹è‚¡æ²Ÿçºµåˆ‡å¯è§ä¸€å¤šå±‚åˆ†å¸ƒçš„æ··åˆå›å£°åŒºï¼Œå®½çª„ä¸ç­‰ï¼Œè¿œç«¯è†¨å¤§ï¼Œè¾¹ç•Œæ•´é½ï¼Œé•¿çº¦4ï½5cmã€‚\nï¼ˆ3ï¼‰è…¹éƒ¨Xçº¿æ£€æŸ¥\n     å¯è§é˜¶æ¢¯çŠ¶æ¶²æ°”å¹³ã€‚",
    "QA_pairs": [
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„è¯Šæ–­åŠè¯Šæ–­ä¾æ®ã€‚",
            "answer": "è¯Šæ–­ï¼šåµŒé¡¿æ€§è…¹è‚¡æ²Ÿæ–œç–åˆå¹¶è‚ æ¢—é˜»ã€‚\n      è¯Šæ–­ä¾æ®ï¼š\n      â‘ å³ä¸‹è…¹ç—›å¹¶è‡ªæ‰ªåŠåŒ…å—3å°æ—¶ï¼›\n      â‘¡æœ‰è…¹èƒ€ã€å‘•åï¼Œç±»ä¼¼è‚ æ¢—é˜»è¡¨ç°ï¼›è…¹éƒ¨å¹³ç‰‡å¯è§é˜¶æ¢¯çŠ¶æ¶²å¹³ï¼Œè€ƒè™‘è‚ æ¢—é˜»å¯èƒ½ï¼›è…¹éƒ¨Bè¶…è€ƒè™‘ï¼Œ \nè…¹éƒ¨åŒ…å—å†…å¯èƒ½ä¸ºè‚ ç®¡å¯èƒ½ï¼›\n      â‘¢æœ‰è½»åº¦æ¯’æ€§ååº”æˆ–æ˜¯ä¸­æ¯’ååº”ï¼Œå¦‚ T 37.8â„ƒï¼ŒP 101æ¬¡ï¼åˆ†ï¼Œç™½ç»†èƒä¸­æ€§åˆ†ç±»78ï¼…ï¼›\n      â‘£è…¹è‚¡æ²ŸåŒºåŒ…å—ä½äºè…¹è‚¡æ²ŸéŸ§å¸¦ä¸Šå†…æ–¹ã€‚"
        },
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„é‰´åˆ«è¯Šæ–­ã€‚",
            "answer": "ï¼ˆ1ï¼‰ç¾ä¸¸é˜è†œç§¯æ¶²ï¼šé˜è†œç§¯æ¶²æ‰€å‘ˆç°çš„è‚¿å—å®Œå…¨å±€é™åœ¨é˜´å›Šå†…ï¼Œå…¶ä¸Šç•Œå¯ä»¥æ¸…æ¥šåœ°æ‘¸åˆ°ï¼›ç”¨é€å…‰è¯•éªŒæ£€æŸ¥è‚¿å—ï¼Œé˜è†œç§¯æ¶²å¤šä¸ºé€å…‰ï¼ˆé˜³æ€§ï¼‰ï¼Œè€Œç–å—åˆ™ä¸èƒ½é€å…‰ã€‚\n     ï¼ˆ2ï¼‰äº¤é€šæ€§é˜è†œç§¯æ¶²ï¼šè‚¿å—çš„å¤–å½¢ä¸ç¾ä¸¸é˜è†œç§¯æ¶²ç›¸ä¼¼ã€‚äºæ¯æ—¥èµ·åºŠåæˆ–ç«™ç«‹æ´»åŠ¨æ—¶è‚¿å—ç¼“æ…¢åœ°å‡ºç°å¹¶å¢å¤§ã€‚å¹³å§æˆ–ç¡è§‰åè‚¿å—é€æ¸ç¼©å°ï¼ŒæŒ¤å‹è‚¿å—ï¼Œå…¶ä½“ç§¯ä¹Ÿå¯é€æ¸ç¼©å°ã€‚é€å…‰è¯•éªŒä¸ºé˜³æ€§ã€‚\n     ï¼ˆ3ï¼‰ç²¾ç´¢é˜è†œç§¯æ¶²ï¼šè‚¿å—è¾ƒå°ï¼Œåœ¨è…¹è‚¡æ²Ÿç®¡å†…ï¼Œç‰µæ‹‰åŒä¾§ç¾ä¸¸å¯è§è‚¿å—ç§»åŠ¨ã€‚\n     ï¼ˆ4ï¼‰éšç¾ï¼šè…¹è‚¡æ²Ÿç®¡å†…ä¸‹é™ä¸å…¨çš„ç¾ä¸¸å¯è¢«è¯¯è¯Šä¸ºæ–œç–æˆ–ç²¾ç´¢é˜è†œç§¯æ¶²ã€‚éšç¾è‚¿å—è¾ƒå°ï¼ŒæŒ¤å‹æ—¶å¯å‡ºç°ç‰¹æœ‰çš„èƒ€ç—›æ„Ÿè§‰ã€‚å¦‚æ‚£ä¾§é˜´å›Šå†…ç¾ä¸¸ç¼ºå¦‚ï¼Œåˆ™è¯Šæ–­æ›´ä¸ºæ˜ç¡®ã€‚\n     ï¼ˆ5ï¼‰æ€¥æ€§è‚ æ¢—é˜»ï¼šè‚ ç®¡è¢«åµŒé¡¿çš„ç–å¯ä¼´å‘æ€¥æ€§è‚ æ¢—é˜»ï¼Œä½†ä¸åº”ä»…æ»¡è¶³äºè‚ æ¢—é˜»çš„è¯Šæ–­è€Œå¿½ç•¥ç–çš„å­˜åœ¨ï¼›å°¤å…¶æ˜¯ç—…äººæ¯”è¾ƒè‚¥èƒ–æˆ–ç–å—è¾ƒå°æ—¶ï¼Œæ›´æ˜“å‘ç”Ÿè¿™ç±»é—®é¢˜è€Œå¯¼è‡´æ²»ç–—ä¸Šçš„é”™è¯¯ã€‚\n     ï¼ˆ6ï¼‰æ­¤å¤–ï¼Œè…¹è‚¡æ²ŸåŒºè‚¿å—è¿˜åº”ä¸ä»¥ä¸‹ç–¾ç—…é‰´åˆ«:è‚¿å¤§çš„æ·‹å·´ç»“ã€åŠ¨ï¼ˆé™ï¼‰è„‰ç˜¤ã€è½¯ç»„ç»‡è‚¿ç˜¤ã€è„“è‚¿ã€\nåœ†éŸ§å¸¦å›Šè‚¿ã€å­å®«å†…è†œå¼‚ä½ç—‡ç­‰ã€‚"
        },
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„æ²»ç–—åŸåˆ™ã€‚",
            "answer": "åµŒé¡¿æ€§ç–åŸåˆ™ä¸Šéœ€è¦ç´§æ€¥æ‰‹æœ¯æ²»ç–—ï¼Œä»¥é˜²æ­¢ç–å†…å®¹ç‰©åæ­»å¹¶è§£é™¤ä¼´å‘çš„è‚ æ¢—é˜»ã€‚æœ¯å‰åº”åšå¥½å¿…è¦çš„å‡†å¤‡ï¼Œå¦‚æœ‰è„±æ°´å’Œç”µè§£è´¨ç´Šä¹±ï¼Œåº”è¿…é€Ÿè¡¥æ¶²åŠ ä»¥çº æ­£ã€‚æ‰‹æœ¯çš„å…³é”®åœ¨äºæ­£ç¡®åˆ¤æ–­ç–å†…å®¹ç‰©çš„æ´»åŠ›ï¼Œç„¶åæ ¹æ®ç—…æƒ…ç¡®å®šå¤„ç†æ–¹æ³•ã€‚åœ¨æ‰©å¼ æˆ–åˆ‡å¼€ç–ç¯ã€è§£é™¤ç–ç¯å‹è¿«çš„å‰æä¸‹ï¼Œå‡¡è‚ ç®¡å‘ˆç´«é»‘è‰²ï¼Œå¤±å»å…‰æ³½å’Œå¼¹æ€§ï¼Œåˆºæ¿€åæ— è •åŠ¨å’Œç›¸åº”è‚ ç³»è†œå†…æ— åŠ¨è„‰æåŠ¨è€…ï¼Œå³å¯åˆ¤å®šä¸ºè‚ åæ­»ã€‚å¦‚è‚ ç®¡å°šæœªåæ­»ï¼Œåˆ™å¯å°†å…¶é€å›è…¹è…”ï¼ŒæŒ‰ä¸€èˆ¬æ˜“å¤æ€§ç–å¤„ç†ï¼Œå³è¡Œç–å›Šé«˜ä½ç»“æ‰+ç–ä¿®è¡¥æœ¯ã€‚å¦‚è‚ ç®¡ç¡®å·²åæ­»æˆ–ä¸€æ—¶ä¸èƒ½è‚¯å®šè‚ ç®¡æ˜¯å¦å·²å¤±å»æ´»åŠ›æ—¶ï¼Œåˆ™åº”åœ¨ç—…äººå…¨èº«æƒ…å†µå…è®¸çš„å‰æä¸‹ï¼Œåˆ‡é™¤è¯¥æ®µè‚ ç®¡å¹¶è¿›è¡Œä¸€æœŸå»åˆã€‚å‡¡æ–½è¡Œè‚ åˆ‡é™¤å»åˆæœ¯çš„ç—…äººï¼Œå› æ‰‹æœ¯åŒºæ±¡æŸ“ï¼Œåœ¨é«˜ä½ç»“æ‰ç–å›Šåï¼Œä¸€èˆ¬ä¸å®œä½œç–ä¿®è¡¥æœ¯ï¼Œä»¥å…å› æ„ŸæŸ“è€Œè‡´ä¿®è¡¥å¤±è´¥ã€‚"
        }
    ]
}
```
- title: ç—…ä¾‹ç–¾ç—…åç§°;
- description: ç—…ä¾‹ä¿¡æ¯;
- QA_pairs: ä¸€ç³»åˆ—è¯Šæ–­é—®é¢˜å’Œå¯¹åº”æ ‡å‡†å›ç­”;





## â„¹ï¸ å¦‚ä½•è¿›è¡Œè¯„æµ‹å’Œæäº¤

### ä¿®æ”¹æ¨¡å‹é…ç½®æ–‡ä»¶
<details><summary>Click to expand</summary>

`configs/model_config.yaml`ï¼š
```
my_model:
    model_id: 'my_model'
    load:
        # # HuggingFace model weights
        config_dir: "path/to/full/model"

        # # load with Peft
        # llama_dir: "path/to/base"
        # lora_dir: "path/to/lora"

        device: 'cuda'          # only support cuda
        precision: 'fp16'       # 

    # supports all parameters in transformers.GenerationConfig
    generation_config: 
        max_new_tokens: 512     
        min_new_tokens: 1          
        do_sample: False         
```
</details>


### ä¿®æ”¹æ¨¡å‹worker

<details><summary>Click to expand</summary>

`workers/mymodel.py` ç¤ºä¾‹å¦‚ä¸‹ï¼š
1. load model and tokenizer to cpu
   ```
   def load_model_and_tokenizer(self, load_config):
        '''
        Params: 
            load_config: the `load` key in `configs/model_config.yaml`
        Returns:
            model, tokenizer: both on cpu
        '''
        hf_model_config = {"pretrained_model_name_or_path": load_config['config_dir'],'trust_remote_code': True, 'low_cpu_mem_usage': True}
        hf_tokenizer_config = {"pretrained_model_name_or_path": load_config['config_dir'], 'padding_side': 'left', 'trust_remote_code': True}
        precision = load_config.get('precision', 'fp16')
        device = load_config.get('device', 'cuda')
   
        if precision == 'fp16':
            hf_model_config.update({"torch_dtype": torch.float16})
   
        model = AutoModelForCausalLM.from_pretrained(**hf_model_config)
        tokenizer = AutoTokenizer.from_pretrained(**hf_tokenizer_config)
   
        model.eval()
        return model, tokenizer # cpu
   ```

2. system prompt
    ```
    @property
    def system_prompt(self):
        '''
        The prompt that is prepended to every input.
        '''
        return "ä½ æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚"
    ```

3. instruction template
    ```
    @property
    def instruction_template(self):
        '''
        The template for instruction input. An '{instruction}' placeholder must be contained.
        '''
        return self.system_prompt + 'é—®ï¼š{instruction}\nç­”ï¼š'
    ```

4. instruction template with fewshot examples
    ```
    @property
    def instruction_template_with_fewshot(self,):
        '''
        The template for instruction input. There must be an '{instruction}' placeholder in this template.
        '''
        return self.system_prompt + '{fewshot_examples}é—®ï¼š{instruction}\nç­”ï¼š'  # å¿…é¡»å¸¦æœ‰ {instruction} å’Œ {fewshot_examples} çš„placeholder
    ```
    
5. template for each fewshot example
    ```
    @property
    def fewshot_template(self):
        '''
        The template for each fewshot example. Each fewshot example is concatenated and put in the `{fewshot_examples}` placeholder above.
        There must be a `{user}` and `{gpt}` placeholder in this template.
        '''
        return "é—®ï¼š{user}\nç­”ï¼š{gpt}\n" # å¿…é¡»å¸¦æœ‰ {user} å’Œ {gpt} çš„placeholder
    ```
    </details>


### ä¿®æ”¹ /src/constants.py
<details><summary>Click to expand</summary>

```python
from workers.mymodel import MyModelWorker # modify here
id2worker_class = {
"my_model": MyModelWorker,  # modify here
}
```
</details>

### ç”Ÿæˆfewshot prompt (å¦‚æœä½¿ç”¨fewshot prompt)
<details><summary>Click to expand</summary>

`generate_fewshot.sh` ç¤ºä¾‹å¦‚ä¸‹ï¼š
```bash
model_id="baichuan-13b-chat"
n_shot=3

test_path=data/CMB-Exam/CMB-test/CMB-test-choice-question-merge.json 
val_path=data/CMB-Exam/CMB-val/CMB-val-merge.json
output_dir=data/fewshot
python ./src/generate_fewshot.py \
--use_cot \                     # whether to use CoT template
--n_shot=$n_shot \
--model_id=$model_id \
--output_dir=$output_dir  \
--val_path=$val_path \
--test_path=$test_path 
```

å¹¶è¿è¡Œ:
```bash
bash generate_fewshot.sh

```

</details>


### ä¿®æ”¹è¿è¡Œè„šæœ¬
<details><summary>Click to expand</summary>

`generate_answers.sh` ç¤ºä¾‹å¦‚ä¸‹ï¼š

```
# # è¾“å…¥æ–‡ä»¶è·¯å¾„
# test_data_path='./data/CMB-Exam/CMB-test/CMB-test-choice-question-merge.json'   # åŒ»ç–—æ¨¡å‹èƒ½åŠ›æµ‹è¯„æ•°æ®é›†
# test_data_path='./data/CMB-test-qa/CMB-test-qa.json'                            # çœŸå®ç—…ä¾‹è¯Šæ–­èƒ½åŠ›æµ‹è¯„æ•°æ®é›†


task_name='Zero-test-cot'   
port_id=27272

model_id="my_model"                                                      # æ¨¡å‹idï¼Œåº”ä¸`./configs/model_config.yaml` ä¸­æ·»åŠ çš„model_idä¿æŒä¸€è‡´

accelerate launch \
    --gpu_ids='all' \                                                   # ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
    --main_process_port $port_id \                                      # ç«¯å£
    --config_file ./configs/accelerate_config.yaml  \                   # accelerate é…ç½®æ–‡ä»¶è·¯å¾„
    ./src/generate_answers.py \                                         # ä¸»ç¨‹åº
    --model_id=$model_id \                                              # æ¨¡å‹ID
    --cot_flag \                                                        # æ˜¯å¦ä½¿ç”¨CoT promptæ¨¡æ¿                                   
    --batch_size 3\                                                      # æ¨ç†çš„batch size                                 
    --input_path=$test_data_path \                                      # è¾“å…¥æ–‡ä»¶è·¯å¾„
    --output_path=./result/${task_name}/${model_id}/answers.json \      # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    --model_config_path="./configs/model_config.yaml"                   # æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
```
</details>

### è¯„æµ‹å’Œæäº¤ç»“æœ
<details><summary>Click to expand</summary>

Step 1: ç”Ÿæˆå›ç­” + æŠ½å–ç­”æ¡ˆ
```
bash generate_answers.sh
```

Step 2: è®¡ç®—å¾—åˆ† + æäº¤ç»“æœ
å°†**Step 1**çš„è¾“å‡ºæ–‡ä»¶æäº¤è‡³[å®˜ç½‘](https://cmedbenchmark.llmzoo.com/static/submit.html)å¹¶ä¸‹è½½åˆ†æ•°æŠ¥å‘Šã€‚å¦‚æœæ‚¨å¸Œæœ›å…¬å¼€æ¨¡å‹çš„è¡¨ç°ï¼Œæ•¬è¯·å°†ç›¸å…³ç»“æœè¿åŒæ¨¡å‹åç§°å’Œæœºæ„ä¿¡æ¯å‘é€è‡³cmedbenchmark@163.comã€‚æˆ‘ä»¬å°†å°½å¿«è¿›è¡Œå®¡æ ¸ä¸æ›´æ–°ã€‚

</details>

## æé«˜æ€§èƒ½çš„æŠ€å·§
### å°è¯•ä¸åŒçš„è§£ç ç­–ç•¥
æ‚¨å¯ä»¥åœ¨`./configs/model_config.yaml`ä¸­é…ç½®ç”¨äºç”Ÿæˆçš„è¶…å‚æ•°ã€‚æˆ‘ä»¬å‘ç°ï¼Œå¯¹äºå¤§å¤šæ•°æ¨¡å‹æ¥è¯´ï¼Œè¾ƒä½çš„æ¸©åº¦é€šå¸¸ä¼šå¸¦æ¥æ›´é«˜çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…¶ä»–è¶…å‚æ•°çš„å½±å“å°šä¸æ¸…æ¥šã€‚

### ä¿®æ”¹ç­”æ¡ˆåŒ¹é…ç­–ç•¥
æ‚¨å¯ä»¥ä¿®æ”¹`src/utils.py`ä¸­çš„`match_choice()`å‡½æ•°ã€‚ ä¸åŒæ¨¡å‹çš„è¾“å‡ºæ¨¡å¼å„ä¸ç›¸åŒï¼Œè¿™ä½¿å¾—æˆ‘ä»¬å¾ˆéš¾ä½¿ç”¨å•ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ¥è€ƒè™‘æ‰€æœ‰æ¨¡å‹çš„æ‰€æœ‰æƒ…å†µã€‚ å¦‚æœæ‚¨åœ¨æˆ‘ä»¬çš„è®ºæ–‡ä¸­ä¸ºè¿™äº›è¯„ä¼°æ¨¡å‹æ‰¾åˆ°äº†æ›´å¥½çš„åŒ¹é…ç­–ç•¥ï¼Œè¯·æäº¤æ‚¨çš„ç»“æœä»¥è¿›è¡Œæ›´æ–°ã€‚



## æç¤ºæ ¼å¼
### CMB-Exam Prompt
[CMB-Exam Item](#cmb-exam-item)
#### Answer-only Prompt
```
{System_prompt}

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œä¸éœ€è¦åšä»»ä½•åˆ†æå’Œè§£é‡Šï¼Œç›´æ¥è¾“å‡ºç­”æ¡ˆé€‰é¡¹ã€‚ã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼šA

[n-shot demo, n is 0 for the zero-shot case]

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œä¸éœ€è¦åšä»»ä½•åˆ†æå’Œè§£é‡Šï¼Œç›´æ¥è¾“å‡ºç­”æ¡ˆé€‰é¡¹ã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š
```
#### Chain-of-thought Prompt

```
{System_prompt}

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œè¯·åˆ†ææ¯ä¸ªé€‰é¡¹ï¼Œå¹¶æœ€åç»™å‡ºç­”æ¡ˆã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š.......æ‰€ä»¥ç­”æ¡ˆæ˜¯A

[n-shot demo, n is 0 for the zero-shot case]

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œè¯·åˆ†ææ¯ä¸ªé€‰é¡¹ï¼Œå¹¶æœ€åç»™å‡ºç­”æ¡ˆã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š
```

### CMB-Clin Prompt
[CMB-Clin Item](#cmb-clin-item) 
```
{System_prompt}

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸€ä½ç—…äººçš„ç—…ä¾‹ï¼š
{description}
{QA_pairs[0]['question']}
<{Role_2}>ï¼š..........
[n-question based on the len(QA_pairs)]
```

### CMB-Clin GPT-4 evaluation Prompt

<details><summary>Click to expand</summary>

```
You are an AI evaluator specializing in assessing the quality of answers
provided by other language models . Your primary goal is to rate the
answers based on their fluency , relevance , completeness , proficiency
in medicine . Use the following scales to evaluate each criterion :
Fluency :
1: Completely broken and unreadable sentence pieces
2: Mostly broken with few readable tokens
3: Moderately fluent but with limited vocabulary
4: Mostly coherent in expressing complex subjects
5: Human - level fluency
Relevance :
1: Completely unrelated to the question
2: Some relation to the question , but mostly off - topic
3: Relevant , but lacking focus or key details
4: Highly relevant , addressing the main aspects of the question
5: Directly relevant and precisely targeted to the question
Completeness :
1: Extremely incomplete
2: Almost incomplete with limited information
3: Moderate completeness with some information
4: Mostly complete with most of the information displayed
5: Fully complete with all information presented
Proficiency in medicine :
1: Using plain languages with no medical terminology .
2: Equipped with some medical knowledge but lacking in - depth details
3: Conveying moderately complex medical information with clarity
4: Showing solid grasp of medical terminology but having some minor
mistakes in detail
5: Fully correct in all presented medical knowledge
You will be provided with the following information :
- a description
- a conversation based on the description ( optional )
- a question based on the description and conversation
- the solution to the question
- a model â€™ s answer to the question
[ description ]
{ description }
[ end of description ]
[ conversation ]
{ history }
[ end of conversation ]
[ question ]
{ question }
[ end of question ]
[ solution ]
{ solution }
[ end of solution ]
[ answer ]
{ answer }
[ end of answer ]
Make sure to provide your evaluation results in JSON format and ONLY the
JSON , with separate ratings for each of the mentioned criteria as in
the following example :
{ â€˜ fluency â€™: 3 , â€˜ relevance â€™: 3 , â€˜ completeness â€™: 3 , â€˜ proficiency â€™: 3}
```

</details>

<!-- ## ä¸€äº›é™åˆ¶

1. CMB-Clin å·²å˜ä¸ºå¤šè½®å¯¹è¯
2. ç­”æ¡ˆæå–æ–¹å¼å¯èƒ½ä¸å¤Ÿå®Œå–„, è¯¦è§[ä»£ç ](https://github.com/FreedomIntelligence/CMB/blob/main/src/utils.py#L36)ã€‚ -->



## å¼•ç”¨
å¦‚æœæ‚¨æ‰“ç®—ä½¿ç”¨æˆ‘ä»¬çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒæˆ–è¯„ä¼°ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å¼•ç”¨ï¼š

```
@misc{wang2023cmb,
      title={CMB: A Comprehensive Medical Benchmark in Chinese}, 
      author={Xidong Wang and Guiming Hardy Chen and Dingjie Song and Zhiyi Zhang and Zhihong Chen and Qingying Xiao and Feng Jiang and Jianquan Li and Xiang Wan and Benyou Wang and Haizhou Li},
      year={2023},
      eprint={2308.08833},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```


```
@misc{cmedbenchmark,
  title={CMB: Chinese Medical Benchmark},
  author={Xidong Wang*, Guiming Hardy Chen*, Dingjie Song*, Zhiyi Zhang*, Qingying Xiao*, Xiangbo Wu, Feng Jiang, Jianquan Li, Benyou Wang},
  note={Authors Xidong Wang, Guiming Hardy Chen, Dingjie Song, Zhiyi Zhang and Qingying Xiao contributed equally to this work.},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/FreedomIntelligence/CMB}},
}

```

## è‡´è°¢
- æ„Ÿè°¢[æ·±åœ³å¸‚å¤§æ•°æ®ç ”ç©¶é™¢](http://www.sribd.cn/)å¯¹æ­¤é¡¹ç›®æä¾›çš„å¤§åŠ›æ”¯æŒã€‚
- æˆ‘ä»¬æ„Ÿè°¢ä»¥ä¸‹åŒ»ç”Ÿå‚ä¸CMB-Clinçš„åŒ»ç”Ÿè¯„ä¼°:
    - æ—å£«å†› (é¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰é™„å±ç¬¬äºŒåŒ»é™¢)
    - å¸¸æ²³
    - è®¸æ™“çˆ½
