# CMB Chinese-Medical-Benchmark 
<p align="center">
   ğŸŒ <a href="https://cmedbenchmark.llmzoo.com/#home" target="_blank">Website</a> â€¢ ğŸ¤— <a href="https://huggingface.co/datasets/FreedomIntelligence/CMB" target="_blank">Hugging Face</a>

## ğŸŒˆ æ›´æ–°

* **[2023.07.25]** ğŸ‰ğŸ‰ğŸ‰ CMBå…¬å¼€ï¼æ„Ÿè°¢æ”¯æŒ~ğŸ‰ğŸ‰ğŸ‰



## ğŸŒ æ•°æ®ä¸‹è½½

- æ–¹æ³•ä¸€ï¼šç›´æ¥ä¸‹è½½ä½¿ç”¨[zipå‹ç¼©æ–‡ä»¶](https://github.com/FreedomIntelligence/CMB/tree/main/data)
- æ–¹æ³•äºŒï¼šä½¿ç”¨[Hugging Face datasets](https://huggingface.co/datasets/FreedomIntelligence/CMB)ç›´æ¥åŠ è½½æ•°æ®é›† ç¤ºä¾‹å¦‚ä¸‹:
  ```python
  from datasets import load_dataset
  
  # main datasets ï¼ˆmultiple choiceï¼‰
  main_datasets = load_dataset('FreedomIntelligence/CMB','main')
  # exam paper datasets ï¼ˆmultiple choiceï¼‰
  exam_datasets = load_dataset('FreedomIntelligence/CMB','exampaper')
  # QA datasets
  qa_datasets = load_dataset('FreedomIntelligence/CMB','qa')
  ```



## ğŸ¥‡ æ’è¡Œæ¦œ

æˆ‘ä»¬è¯„ä¼°äº†æ¨¡å‹çš„zero-shotå‡†ç¡®ç‡ï¼Œè¯·è®¿é—®æˆ‘ä»¬[å®˜æ–¹æ’è¡Œæ¦œ](https://cmedbenchmark.llmzoo.com/static/leaderboard.html)äº†è§£è¯¦ç»†ç»“æœã€‚



## ğŸ¥¸ æ•°æ®é›†ä»‹ç»
![CMB](assets/CMB.png)
### ç»„æˆéƒ¨åˆ†
- CMB-main: å…¨æ–¹ä½å¤šå±‚æ¬¡æµ‹è¯„æ¨¡å‹åŒ»ç–—çŸ¥è¯†;
   - ç»“æ„: 6å¤§é¡¹28å°é¡¹ï¼Œè¯¦è§ä¸Šå›¾CMB-Main, [ç›®å½•åœ°å€](catalog.md);
   - CMB-test: 11200é“é¢˜ç›®ï¼Œæ¯ä¸€å°é¡¹400é“é¢˜ç›®; 
   - CMB-val: 280é“é™„å¸¦è¯¦ç»†è§£æçš„é¢˜ç›®; Few Shotæ•°æ®é›†;
   - CMB-train: 269359é“é¢˜ç›®; æ¨¡å‹åŒ»ç–—çŸ¥è¯†æ³¨å…¥;
    
- CME-qa: æµ‹è¯„å¤æ‚ä¸´åºŠé—®è¯Šèƒ½åŠ›
   - æ•°æ®: 73ä¾‹å¤æ‚ç—…ä¾‹é—®è¯Š;
- CMB-exampaper: æµ‹è¯„æ¨¡å‹æ˜¯å¦é€šè¿‡è€ƒè¯•
   - æ•°æ®: 9å°é¡¹ï¼Œ25å¥—å…±6571é“é¢˜ç›®ï¼Œè¯¦è§ä¸Šå›¾CMB-Exam, [å¥—é¢˜ç›®å½•åœ°å€](exam-catalog.md);


### CMB-main & CME-exampaper Item 
```json
{
    "exam_type": "åŒ»å¸ˆè€ƒè¯•",
    "exam_class": "æ‰§ä¸šåŒ»å¸ˆ",
    "exam_subject": "å£è…”æ‰§ä¸šåŒ»å¸ˆ",
    "question": "æ‚£è€…ï¼Œç”·æ€§ï¼Œ11å²ã€‚è¿‘2ä¸ªæœˆæ¥æ—¶æœ‰ä½çƒ­ï¼ˆ37ï½38â„ƒï¼‰ï¼Œå…¨èº«æ— æ˜æ˜¾ç—‡çŠ¶ã€‚æŸ¥ä½“æ— æ˜æ˜¾é˜³æ€§ä½“å¾ã€‚Xçº¿æ£€æŸ¥å‘ç°å³è‚ºä¸­éƒ¨æœ‰ä¸€ç›´å¾„çº¦0.8cmç±»åœ†å½¢ç—…ç¶ï¼Œè¾¹ç¼˜ç¨æ¨¡ç³Šï¼Œè‚ºé—¨æ·‹å·´ç»“è‚¿å¤§ã€‚æ­¤ç”·å­©å¯èƒ½æ‚£",
    "answer": "D",
    "question_type": "å•é¡¹é€‰æ‹©é¢˜",
    "option": {
        "A": "å°å¶å‹è‚ºç‚",
        "B": "æµ¸æ¶¦æ€§è‚ºç»“æ ¸",
        "C": "ç»§å‘æ€§è‚ºç»“æ ¸",
        "D": "åŸå‘æ€§è‚ºç»“æ ¸",
        "E": "ç²Ÿç²’å‹è‚ºç»“æ ¸"
    }
},
```
- exam_type: å¤§é¡¹åˆ†ç±»; 
- exam_class: å°é¡¹åˆ†ç±»; 
- exam_subject: å…·ä½“ç§‘å®¤æˆ–ç»†åˆ†å­¦ç§‘åˆ†ç±»; 
- question_type: åªæœ‰"å•é¡¹é€‰æ‹©é¢˜"å’Œ"å¤šé¡¹é€‰æ‹©é¢˜";

### CMB-qa Item 
```json
{
    "id": "0",
    "title": "æ¡ˆä¾‹åˆ†æ-è…¹å¤–ç–",
    "description": "ç°ç—…å²\nï¼ˆ1ï¼‰ç—…å²æ‘˜è¦\n     ç—…äººï¼Œç”·ï¼Œ49å²ï¼Œ3å°æ—¶å‰è§£å¤§ä¾¿åå‡ºç°å³ä¸‹è…¹ç–¼ç—›ï¼Œå³ä¸‹è…¹å¯è§¦åŠä¸€åŒ…å—ï¼Œæ—¢å¾€ä½“å¥ã€‚\nï¼ˆ2ï¼‰ä¸»è¯‰\n     å³ä¸‹è…¹ç—›å¹¶è‡ªæ‰ªåŠåŒ…å—3å°æ—¶ã€‚\n\nä½“æ ¼æ£€æŸ¥\nä½“æ¸©ï¼š T 37.8â„ƒï¼ŒP 101æ¬¡ï¼åˆ†ï¼Œå‘¼å¸22æ¬¡/åˆ†ï¼ŒBP 100/60mmHgï¼Œè…¹è½¯ï¼Œæœªè§èƒƒè‚ å‹è •åŠ¨æ³¢ï¼Œè‚è„¾è‚‹ä¸‹æœªåŠï¼Œäºå³ä¾§è…¹è‚¡æ²ŸåŒºå¯æ‰ªåŠä¸€åœ†å½¢è‚¿å—ï¼Œçº¦4cmÃ—4cmå¤§å°ï¼Œæœ‰å‹ç—›ã€ç•Œæ¬ æ¸…ï¼Œä¸”è‚¿å—ä½äºè…¹è‚¡æ²ŸéŸ§å¸¦ä¸Šå†…æ–¹ã€‚\n\nè¾…åŠ©æ£€æŸ¥\nï¼ˆ1ï¼‰å®éªŒå®¤æ£€æŸ¥\n     è¡€å¸¸è§„ï¼šWBC 5.0Ã—109ï¼Lï¼ŒN 78ï¼…ã€‚\n     å°¿å¸¸è§„æ­£å¸¸ã€‚\nï¼ˆ2ï¼‰å¤šæ™®å‹’è¶…å£°æ£€æŸ¥\n     æ²¿è…¹è‚¡æ²Ÿçºµåˆ‡å¯è§ä¸€å¤šå±‚åˆ†å¸ƒçš„æ··åˆå›å£°åŒºï¼Œå®½çª„ä¸ç­‰ï¼Œè¿œç«¯è†¨å¤§ï¼Œè¾¹ç•Œæ•´é½ï¼Œé•¿çº¦4ï½5cmã€‚\nï¼ˆ3ï¼‰è…¹éƒ¨Xçº¿æ£€æŸ¥\n     å¯è§é˜¶æ¢¯çŠ¶æ¶²æ°”å¹³ã€‚",
    "QA_pairs": [
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„è¯Šæ–­åŠè¯Šæ–­ä¾æ®ã€‚",
            "answer": "è¯Šæ–­ï¼šåµŒé¡¿æ€§è…¹è‚¡æ²Ÿæ–œç–åˆå¹¶è‚ æ¢—é˜»ã€‚\n      è¯Šæ–­ä¾æ®ï¼š\n      â‘ å³ä¸‹è…¹ç—›å¹¶è‡ªæ‰ªåŠåŒ…å—3å°æ—¶ï¼›\n      â‘¡æœ‰è…¹èƒ€ã€å‘•åï¼Œç±»ä¼¼è‚ æ¢—é˜»è¡¨ç°ï¼›è…¹éƒ¨å¹³ç‰‡å¯è§é˜¶æ¢¯çŠ¶æ¶²å¹³ï¼Œè€ƒè™‘è‚ æ¢—é˜»å¯èƒ½ï¼›è…¹éƒ¨Bè¶…è€ƒè™‘ï¼Œ \nè…¹éƒ¨åŒ…å—å†…å¯èƒ½ä¸ºè‚ ç®¡å¯èƒ½ï¼›\n      â‘¢æœ‰è½»åº¦æ¯’æ€§ååº”æˆ–æ˜¯ä¸­æ¯’ååº”ï¼Œå¦‚ T 37.8â„ƒï¼ŒP 101æ¬¡ï¼åˆ†ï¼Œç™½ç»†èƒä¸­æ€§åˆ†ç±»78ï¼…ï¼›\n      â‘£è…¹è‚¡æ²ŸåŒºåŒ…å—ä½äºè…¹è‚¡æ²ŸéŸ§å¸¦ä¸Šå†…æ–¹ã€‚"
        },
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„é‰´åˆ«è¯Šæ–­ã€‚",
            "answer": "ï¼ˆ1ï¼‰ç¾ä¸¸é˜è†œç§¯æ¶²ï¼šé˜è†œç§¯æ¶²æ‰€å‘ˆç°çš„è‚¿å—å®Œå…¨å±€é™åœ¨é˜´å›Šå†…ï¼Œå…¶ä¸Šç•Œå¯ä»¥æ¸…æ¥šåœ°æ‘¸åˆ°ï¼›ç”¨é€å…‰è¯•éªŒæ£€æŸ¥è‚¿å—ï¼Œé˜è†œç§¯æ¶²å¤šä¸ºé€å…‰ï¼ˆé˜³æ€§ï¼‰ï¼Œè€Œç–å—åˆ™ä¸èƒ½é€å…‰ã€‚\n     ï¼ˆ2ï¼‰äº¤é€šæ€§é˜è†œç§¯æ¶²ï¼šè‚¿å—çš„å¤–å½¢ä¸ç¾ä¸¸é˜è†œç§¯æ¶²ç›¸ä¼¼ã€‚äºæ¯æ—¥èµ·åºŠåæˆ–ç«™ç«‹æ´»åŠ¨æ—¶è‚¿å—ç¼“æ…¢åœ°å‡ºç°å¹¶å¢å¤§ã€‚å¹³å§æˆ–ç¡è§‰åè‚¿å—é€æ¸ç¼©å°ï¼ŒæŒ¤å‹è‚¿å—ï¼Œå…¶ä½“ç§¯ä¹Ÿå¯é€æ¸ç¼©å°ã€‚é€å…‰è¯•éªŒä¸ºé˜³æ€§ã€‚\n     ï¼ˆ3ï¼‰ç²¾ç´¢é˜è†œç§¯æ¶²ï¼šè‚¿å—è¾ƒå°ï¼Œåœ¨è…¹è‚¡æ²Ÿç®¡å†…ï¼Œç‰µæ‹‰åŒä¾§ç¾ä¸¸å¯è§è‚¿å—ç§»åŠ¨ã€‚\n     ï¼ˆ4ï¼‰éšç¾ï¼šè…¹è‚¡æ²Ÿç®¡å†…ä¸‹é™ä¸å…¨çš„ç¾ä¸¸å¯è¢«è¯¯è¯Šä¸ºæ–œç–æˆ–ç²¾ç´¢é˜è†œç§¯æ¶²ã€‚éšç¾è‚¿å—è¾ƒå°ï¼ŒæŒ¤å‹æ—¶å¯å‡ºç°ç‰¹æœ‰çš„èƒ€ç—›æ„Ÿè§‰ã€‚å¦‚æ‚£ä¾§é˜´å›Šå†…ç¾ä¸¸ç¼ºå¦‚ï¼Œåˆ™è¯Šæ–­æ›´ä¸ºæ˜ç¡®ã€‚\n     ï¼ˆ5ï¼‰æ€¥æ€§è‚ æ¢—é˜»ï¼šè‚ ç®¡è¢«åµŒé¡¿çš„ç–å¯ä¼´å‘æ€¥æ€§è‚ æ¢—é˜»ï¼Œä½†ä¸åº”ä»…æ»¡è¶³äºè‚ æ¢—é˜»çš„è¯Šæ–­è€Œå¿½ç•¥ç–çš„å­˜åœ¨ï¼›å°¤å…¶æ˜¯ç—…äººæ¯”è¾ƒè‚¥èƒ–æˆ–ç–å—è¾ƒå°æ—¶ï¼Œæ›´æ˜“å‘ç”Ÿè¿™ç±»é—®é¢˜è€Œå¯¼è‡´æ²»ç–—ä¸Šçš„é”™è¯¯ã€‚\n     ï¼ˆ6ï¼‰æ­¤å¤–ï¼Œè…¹è‚¡æ²ŸåŒºè‚¿å—è¿˜åº”ä¸ä»¥ä¸‹ç–¾ç—…é‰´åˆ«:è‚¿å¤§çš„æ·‹å·´ç»“ã€åŠ¨ï¼ˆé™ï¼‰è„‰ç˜¤ã€è½¯ç»„ç»‡è‚¿ç˜¤ã€è„“è‚¿ã€\nåœ†éŸ§å¸¦å›Šè‚¿ã€å­å®«å†…è†œå¼‚ä½ç—‡ç­‰ã€‚"
        },
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„æ²»ç–—åŸåˆ™ã€‚",
            "answer": "åµŒé¡¿æ€§ç–åŸåˆ™ä¸Šéœ€è¦ç´§æ€¥æ‰‹æœ¯æ²»ç–—ï¼Œä»¥é˜²æ­¢ç–å†…å®¹ç‰©åæ­»å¹¶è§£é™¤ä¼´å‘çš„è‚ æ¢—é˜»ã€‚æœ¯å‰åº”åšå¥½å¿…è¦çš„å‡†å¤‡ï¼Œå¦‚æœ‰è„±æ°´å’Œç”µè§£è´¨ç´Šä¹±ï¼Œåº”è¿…é€Ÿè¡¥æ¶²åŠ ä»¥çº æ­£ã€‚æ‰‹æœ¯çš„å…³é”®åœ¨äºæ­£ç¡®åˆ¤æ–­ç–å†…å®¹ç‰©çš„æ´»åŠ›ï¼Œç„¶åæ ¹æ®ç—…æƒ…ç¡®å®šå¤„ç†æ–¹æ³•ã€‚åœ¨æ‰©å¼ æˆ–åˆ‡å¼€ç–ç¯ã€è§£é™¤ç–ç¯å‹è¿«çš„å‰æä¸‹ï¼Œå‡¡è‚ ç®¡å‘ˆç´«é»‘è‰²ï¼Œå¤±å»å…‰æ³½å’Œå¼¹æ€§ï¼Œåˆºæ¿€åæ— è •åŠ¨å’Œç›¸åº”è‚ ç³»è†œå†…æ— åŠ¨è„‰æåŠ¨è€…ï¼Œå³å¯åˆ¤å®šä¸ºè‚ åæ­»ã€‚å¦‚è‚ ç®¡å°šæœªåæ­»ï¼Œåˆ™å¯å°†å…¶é€å›è…¹è…”ï¼ŒæŒ‰ä¸€èˆ¬æ˜“å¤æ€§ç–å¤„ç†ï¼Œå³è¡Œç–å›Šé«˜ä½ç»“æ‰+ç–ä¿®è¡¥æœ¯ã€‚å¦‚è‚ ç®¡ç¡®å·²åæ­»æˆ–ä¸€æ—¶ä¸èƒ½è‚¯å®šè‚ ç®¡æ˜¯å¦å·²å¤±å»æ´»åŠ›æ—¶ï¼Œåˆ™åº”åœ¨ç—…äººå…¨èº«æƒ…å†µå…è®¸çš„å‰æä¸‹ï¼Œåˆ‡é™¤è¯¥æ®µè‚ ç®¡å¹¶è¿›è¡Œä¸€æœŸå»åˆã€‚å‡¡æ–½è¡Œè‚ åˆ‡é™¤å»åˆæœ¯çš„ç—…äººï¼Œå› æ‰‹æœ¯åŒºæ±¡æŸ“ï¼Œåœ¨é«˜ä½ç»“æ‰ç–å›Šåï¼Œä¸€èˆ¬ä¸å®œä½œç–ä¿®è¡¥æœ¯ï¼Œä»¥å…å› æ„ŸæŸ“è€Œè‡´ä¿®è¡¥å¤±è´¥ã€‚"
        }
    ]
}
```
- title: ç—…ä¾‹ç–¾ç—…åç§°;
- description: ç—…ä¾‹ä¿¡æ¯;
- QA_pairs: ä¸€ç³»åˆ—è¯Šæ–­é—®é¢˜å’Œå¯¹åº”æ ‡å‡†å›ç­”;





## â„¹ï¸ å¦‚ä½•è¿›è¡Œè¯„æµ‹å’Œæäº¤

### ä¿®æ”¹æ¨¡å‹é…ç½®æ–‡ä»¶
`configs/model_config.yaml` ç¤ºä¾‹å¦‚ä¸‹ï¼š
```
my_model:
    model_id: 'my_model'
    load:
        # HuggingFaceæ¨¡å‹æƒé‡æ–‡ä»¶å¤¹
        config_dir: "path/to/full/model"

        # ä½¿ç”¨peftåŠ è½½LoRAæ¨¡å‹
        # llama_dir: "path/to/base"
        # lora_dir: "path/to/lora"

        device: 'cuda'          # å½“å‰ä»…æ”¯æŒcudaæ¨ç†
        precision: 'fp16'       # æ¨ç†ç²¾åº¦ï¼Œæ”¯æŒ fp16, fp32

    # inferenceè§£ç è¶…å‚,æ”¯æŒ transformers.GenerationConfig çš„æ‰€æœ‰å‚æ•°
    generation_config: 
        max_new_tokens: 512     
        min_new_tokens: 1          
        do_sample: False         

```


### æ·»åŠ æ¨¡å‹åŠ è½½ä»£ç åŠpromptæ ¼å¼
åœ¨ `workers/mymodel.py`ä¸­ä¿®æ”¹ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. åŠ è½½ model å’Œ tokenizer
   ```
   def load_model_and_tokenizer(self, load_config):
        # TODO: load your model here
        hf_model_config = {"pretrained_model_name_or_path": load_config['config_dir'],'trust_remote_code': True, 'low_cpu_mem_usage': True}
        hf_tokenizer_config = {"pretrained_model_name_or_path": load_config['config_dir'], 'padding_side': 'left', 'trust_remote_code': True}
        precision = load_config.get('precision', 'fp16')
        device = load_config.get('device', 'cuda')

        if precision == 'fp16':
            hf_model_config.update({"torch_dtype": torch.float16})

        model = AutoModelForCausalLM.from_pretrained(**hf_model_config)
        tokenizer = AutoTokenizer.from_pretrained(**hf_tokenizer_config)

        model.eval()
        return model, tokenizer # cpu
   ```
2. system prompt
    ```
    @property
    def system_prompt(self):
        return "ä½ æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚"
    ```
3. æŒ‡ä»¤æ¨¡æ¿
    ```
    @property
    def instruction_template(self):
        return self.system_prompt + 'é—®ï¼š{instruction}\nç­”ï¼š' # å¿…é¡»å¸¦æœ‰{instruction}çš„placeholder
    ```
4. fewshotæŒ‡ä»¤æ¨¡æ¿
    ```
    @property
    def instruction_template_with_fewshot(self,):
        return self.system_prompt + '{fewshot_examples}é—®ï¼š{instruction}\nç­”ï¼š'  # å¿…é¡»å¸¦æœ‰ {instruction} å’Œ {fewshot_examples} çš„placeholder
    ```
5. å•è½®å¯¹è¯æ¨¡æ¿ï¼Œç”¨äºç”Ÿæˆæ¨¡å‹fewshotæ•°æ®
    ```
    @property
    def fewshot_template(self):
        return "é—®ï¼š{user}\nç­”ï¼š{gpt}\n" # å¿…é¡»å¸¦æœ‰ {user} å’Œ {gpt} çš„placeholder
    ```




### ä¿®æ”¹è¿è¡Œé…ç½®æ–‡ä»¶
`generate_answers.sh` ç¤ºä¾‹å¦‚ä¸‹ï¼š

```
# # è¾“å…¥æ–‡ä»¶è·¯å¾„
# test_data_path='./data/CMB-main/CMB-test/CMB-test-choice-question-merge.json'   # åŒ»ç–—æ¨¡å‹èƒ½åŠ›æµ‹è¯„æ•°æ®é›†
# test_data_path='./data/CMB-test-exampaper/CMB-test-exam-merge.json'             # çœŸé¢˜æµ‹è¯„æ•°æ®é›†
# test_data_path='./data/CMB-test-qa/CMB-test-qa.json'                            # çœŸå®ç—…ä¾‹è¯Šæ–­èƒ½åŠ›æµ‹è¯„æ•°æ®é›†


task_name='Zero-test-cot'   
port_id=27272

model_id="my_model"                                                      # æ¨¡å‹idï¼Œåº”ä¸`./configs/model_config.yaml` ä¸­æ·»åŠ çš„model_idä¿æŒä¸€è‡´

accelerate launch \
    --gpu_ids='all' \                                                   # ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
    --main_process_port $port_id \                                      # ç«¯å£
    --config_file ./configs/accelerate_config.yaml  \                   # accelerate é…ç½®æ–‡ä»¶è·¯å¾„
    ./src/generate_answers.py \                                         # ä¸»ç¨‹åº
    --model_id=$model_id \                                              # æ¨¡å‹ID
    --cot_flag \                                                        # æ˜¯å¦ä½¿ç”¨CoT promptæ¨¡æ¿                                   
    --batch_size 3\                                                      # æ¨ç†çš„batch size                                 
    --input_path=$test_data_path \                                      # è¾“å…¥æ–‡ä»¶è·¯å¾„
    --output_path=./result/${task_name}/${model_id}/answers.json \      # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    --model_config_path="./configs/model_config.yaml"                   # æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
```


### å¼€å§‹è¯„æµ‹

Step 1: ç”Ÿæˆå›ç­” + æŠ½å–ç­”æ¡ˆ
```
bash generate_answers.sh
```

Step 2: è®¡ç®—å¾—åˆ†
CMB-Exampaper:
```
bash score_exam.sh # Examæ•°æ®é›†
```
CMB-test:
å°†**Step 1**çš„è¾“å‡ºæ–‡ä»¶æäº¤è‡³cmedbenchmark@163.comï¼Œæˆ‘ä»¬å°†åœ¨ç¬¬ä¸€æ—¶é—´è¿”å›è¯¦ç»†æµ‹è¯„ç»“æœã€‚

### æäº¤ç»“æœ   
å°† [å¼€å§‹è¯„æµ‹](#å¼€å§‹è¯„æµ‹) ä¸­ **Step 2** è¾“å‡ºæ–‡ä»¶æäº¤è‡³cmedbenchmark@163.comï¼Œæˆ‘ä»¬å°†åœ¨ç¬¬ä¸€æ—¶é—´æ›´æ–°æ’è¡Œæ¦œã€‚




## âœ…  CMBè¯„æµ‹ç»†èŠ‚
Generateå‚æ•°: ä¸ºäº†å‡å°‘æ–¹å·®ï¼Œä¸€è‡´å°†Sampleè®¾ç½®ä¸ºFalseè¿›è¡ŒGreedy Decodingã€‚
### CMB Test & Train & Exampaper Prompt
[CMB-main Item](#cmb-main--cme-exampaper-item)
#### Answer-only Prompt
```
{System_prompt}

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œä¸éœ€è¦åšä»»ä½•åˆ†æå’Œè§£é‡Šï¼Œç›´æ¥è¾“å‡ºç­”æ¡ˆé€‰é¡¹ã€‚ã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼šA

[n-shot demo, n is 0 for the zero-shot case]

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œä¸éœ€è¦åšä»»ä½•åˆ†æå’Œè§£é‡Šï¼Œç›´æ¥è¾“å‡ºç­”æ¡ˆé€‰é¡¹ã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š
```
#### Chain-of-thought Prompt

```
{System_prompt}

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œè¯·åˆ†ææ¯ä¸ªé€‰é¡¹ï¼Œå¹¶æœ€åç»™å‡ºç­”æ¡ˆã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š.......æ‰€ä»¥ç­”æ¡ˆæ˜¯A

[n-shot demo, n is 0 for the zero-shot case]

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œè¯·åˆ†ææ¯ä¸ªé€‰é¡¹ï¼Œå¹¶æœ€åç»™å‡ºç­”æ¡ˆã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š
```

### CMB-qa Prompt
[CMB-qa Item](#cmb-qa-item) 
```
{System_prompt}

<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸€ä½ç—…äººçš„ç—…ä¾‹ï¼š
{description}
{QA_pairs[0]['question']}
<{Role_2}>ï¼š..........
[n-question based on the len(QA_pairs)]
```

## å±€é™æ€§
1. CMB-qaè¯„æµ‹æ²¡æœ‰é‡‡ç”¨çœŸæ­£çš„å¤šè½®å¯¹è¯è¯„ä¼°ï¼Œè€Œæ˜¯å°†å¤šè½®å¯¹è¯è½¬åŒ–ä¸ºCoTçš„å½¢å¼ï¼ˆä¹Ÿå¯ä»¥è¯´ï¼šè¿™æ ·å¯¹åªç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„æ¨¡å‹æ›´å…¬å¹³ï¼‰
2. ç­”æ¡ˆæå–æ–¹å¼æœ‰Bias, è¯¦è§[ä»£ç ](https://github.com/FreedomIntelligence/CMB/blob/main/src/utils.py#L36)ã€‚

## To do List
1. å‘å¸ƒCMB-main å’Œ CMB-exampaper Few-shotæµ‹è¯„ç»“æœã€‚
2. å‘å¸ƒCMB-qaæµ‹è¯„ç»“æœã€‚
3. å‘å¸ƒè®ºæ–‡æŠ¥å‘Šã€‚


## ğŸ˜˜  å¼•ç”¨

```
@misc{cmedbenchmark,
  title={CMB: Chinese Medical Benchmark},
  author={Xidong Wang*, Guiming Hardy Chen*, Dingjie Song*, Zhiyi Zhang*, Qingying Xiao, Xiangbo Wu, Feng Jiang, Jianquan Li, Benyou Wang},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/FreedomIntelligence/CMB}},
}

```

## è‡´è°¢
æ„Ÿè°¢[æ·±åœ³å¸‚å¤§æ•°æ®ç ”ç©¶é™¢](http://www.sribd.cn/)å¯¹æ­¤é¡¹ç›®æä¾›çš„å¤§åŠ›æ”¯æŒã€‚
