# CMB Chinese-Medical-Benchamrk
<p align="center">
   ğŸŒ <a href="" target="_blank">Website</a> â€¢ ğŸ¤— <a href="" target="_blank">Hugging Face</a> â€¢ ğŸ“ƒ <a href="" target="_blank">Paper</a>  <br>  <a href="">   ä¸­æ–‡</a> | <a href="">English 
</p>

## News

* **[2023.07.23]**  CMB Chinese-Medical-Benchamrk Release

## Leaderboard
Below are zero-shot and five-shot accuracies from the models that we evaluate in the initial release, please visit our official [Leaderboard]() for up-to-date models and their detailed results on each subject.

### Zero-shot

### Five-shot


## Data
### Download
- Method 1: Download the zip file (you can also simply open the following link with the browser):
- Method 2: Directly load the dataset using [Hugging Face datasets]():

### Component
CMB-test: CMB Medical Model Ability Evaluation Dataset
- Data volume: 6 major items and 28 sub-items, each with 400 questions, a total of 11,200 questions, including single-choice and multiple-choice questions;
- Evaluation basis: accuracy ranking;
- Purpose: Multi-faceted evaluation of model capabilities;

CME-test-qa: CMB Real Case Diagnostic Ability Evaluation Dataset
- Data volume: 73 detailed textbook cases and diagnostic questions;
- Evaluation basis: manual evaluation by professional doctors;
- Purpose: To evaluate whether the model has clinical inquiry ability;

CMB-test-zhenti: CMB test test dataset
- Data volume: 3 major items and 9 minor items, 26 sets of questions, a total of 7051 questions;
- Evaluation basis: whether the model passes the test (60 points);
- Purpose: To evaluate whether the model can be deployed;

CMB-val: CMB Few-shot data (with detailed analysis)
- Data volume: each sub-item has 10 tracks, a total of 280 tracks;
- Purpose: Few Shot;

CMB-train: CMB training dataset
- Data volume: 6 major items and 28 minor items, a total of 304,734 questions, including single-choice and multiple-choice questions, see /CMB-train/CMB-train-hierarchy.json for details;
- Purpose: model medical knowledge injection

### Introduction

#### CMB-Test & Train & Zhenti Item 
```json
{
    "exam_type": "åŒ»å¸ˆè€ƒè¯•",
    "exam_class": "æ‰§ä¸šåŒ»å¸ˆ",
    "exam_subject": "å£è…”æ‰§ä¸šåŒ»å¸ˆ",
    "question": "æ‚£è€…ï¼Œç”·æ€§ï¼Œ11å²ã€‚è¿‘2ä¸ªæœˆæ¥æ—¶æœ‰ä½çƒ­ï¼ˆ37ï½38â„ƒï¼‰ï¼Œå…¨èº«æ— æ˜æ˜¾ç—‡çŠ¶ã€‚æŸ¥ä½“æ— æ˜æ˜¾é˜³æ€§ä½“å¾ã€‚Xçº¿æ£€æŸ¥å‘ç°å³è‚ºä¸­éƒ¨æœ‰ä¸€ç›´å¾„çº¦0.8cmç±»åœ†å½¢ç—…ç¶ï¼Œè¾¹ç¼˜ç¨æ¨¡ç³Šï¼Œè‚ºé—¨æ·‹å·´ç»“è‚¿å¤§ã€‚æ­¤ç”·å­©å¯èƒ½æ‚£",
    "answer": "D",
    "question_type": "å•é¡¹é€‰æ‹©é¢˜",
    "option": {
        "A": "å°å¶å‹è‚ºç‚",
        "B": "æµ¸æ¶¦æ€§è‚ºç»“æ ¸",
        "C": "ç»§å‘æ€§è‚ºç»“æ ¸",
        "D": "åŸå‘æ€§è‚ºç»“æ ¸",
        "E": "ç²Ÿç²’å‹è‚ºç»“æ ¸"
    }
},
```
- exam_type: classification of major items; different types of clinical work, and special exams [medical postgraduate entrance examination questions] [subject knowledge points inspection questions];
- exam_class: subcategory; different medical-related occupational grades (see [level catalog](catalog.md) for details) [partially distinguishes between Chinese and Western medicine];
- exam_subject: specific department or subdivision;
- question_type: only "å•é¡¹é€‰æ‹©é¢˜" and "å¤šé¡¹é€‰æ‹©é¢˜";

#### CMB-qa Item 
```json
{
    "id": "0",
    "title": "æ¡ˆä¾‹åˆ†æ-è…¹å¤–ç–",
    "description": "ç°ç—…å²\nï¼ˆ1ï¼‰ç—…å²æ‘˜è¦\n     ç—…äººï¼Œç”·ï¼Œ49å²ï¼Œ3å°æ—¶å‰è§£å¤§ä¾¿åå‡ºç°å³ä¸‹è…¹ç–¼ç—›ï¼Œå³ä¸‹è…¹å¯è§¦åŠä¸€åŒ…å—ï¼Œæ—¢å¾€ä½“å¥ã€‚\nï¼ˆ2ï¼‰ä¸»è¯‰\n     å³ä¸‹è…¹ç—›å¹¶è‡ªæ‰ªåŠåŒ…å—3å°æ—¶ã€‚\n\nä½“æ ¼æ£€æŸ¥\nä½“æ¸©ï¼š T 37.8â„ƒï¼ŒP 101æ¬¡ï¼åˆ†ï¼Œå‘¼å¸22æ¬¡/åˆ†ï¼ŒBP 100/60mmHgï¼Œè…¹è½¯ï¼Œæœªè§èƒƒè‚ å‹è •åŠ¨æ³¢ï¼Œè‚è„¾è‚‹ä¸‹æœªåŠï¼Œäºå³ä¾§è…¹è‚¡æ²ŸåŒºå¯æ‰ªåŠä¸€åœ†å½¢è‚¿å—ï¼Œçº¦4cmÃ—4cmå¤§å°ï¼Œæœ‰å‹ç—›ã€ç•Œæ¬ æ¸…ï¼Œä¸”è‚¿å—ä½äºè…¹è‚¡æ²ŸéŸ§å¸¦ä¸Šå†…æ–¹ã€‚\n\nè¾…åŠ©æ£€æŸ¥\nï¼ˆ1ï¼‰å®éªŒå®¤æ£€æŸ¥\n     è¡€å¸¸è§„ï¼šWBC 5.0Ã—109ï¼Lï¼ŒN 78ï¼…ã€‚\n     å°¿å¸¸è§„æ­£å¸¸ã€‚\nï¼ˆ2ï¼‰å¤šæ™®å‹’è¶…å£°æ£€æŸ¥\n     æ²¿è…¹è‚¡æ²Ÿçºµåˆ‡å¯è§ä¸€å¤šå±‚åˆ†å¸ƒçš„æ··åˆå›å£°åŒºï¼Œå®½çª„ä¸ç­‰ï¼Œè¿œç«¯è†¨å¤§ï¼Œè¾¹ç•Œæ•´é½ï¼Œé•¿çº¦4ï½5cmã€‚\nï¼ˆ3ï¼‰è…¹éƒ¨Xçº¿æ£€æŸ¥\n     å¯è§é˜¶æ¢¯çŠ¶æ¶²æ°”å¹³ã€‚",
    "QA_pairs": [
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„è¯Šæ–­åŠè¯Šæ–­ä¾æ®ã€‚",
            "answer": "è¯Šæ–­ï¼šåµŒé¡¿æ€§è…¹è‚¡æ²Ÿæ–œç–åˆå¹¶è‚ æ¢—é˜»ã€‚\n      è¯Šæ–­ä¾æ®ï¼š\n      â‘ å³ä¸‹è…¹ç—›å¹¶è‡ªæ‰ªåŠåŒ…å—3å°æ—¶ï¼›\n      â‘¡æœ‰è…¹èƒ€ã€å‘•åï¼Œç±»ä¼¼è‚ æ¢—é˜»è¡¨ç°ï¼›è…¹éƒ¨å¹³ç‰‡å¯è§é˜¶æ¢¯çŠ¶æ¶²å¹³ï¼Œè€ƒè™‘è‚ æ¢—é˜»å¯èƒ½ï¼›è…¹éƒ¨Bè¶…è€ƒè™‘ï¼Œ \nè…¹éƒ¨åŒ…å—å†…å¯èƒ½ä¸ºè‚ ç®¡å¯èƒ½ï¼›\n      â‘¢æœ‰è½»åº¦æ¯’æ€§ååº”æˆ–æ˜¯ä¸­æ¯’ååº”ï¼Œå¦‚ T 37.8â„ƒï¼ŒP 101æ¬¡ï¼åˆ†ï¼Œç™½ç»†èƒä¸­æ€§åˆ†ç±»78ï¼…ï¼›\n      â‘£è…¹è‚¡æ²ŸåŒºåŒ…å—ä½äºè…¹è‚¡æ²ŸéŸ§å¸¦ä¸Šå†…æ–¹ã€‚"
        },
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„é‰´åˆ«è¯Šæ–­ã€‚",
            "answer": "......"
        },
        {
            "question": "ç®€è¿°è¯¥ç—…äººçš„æ²»ç–—åŸåˆ™ã€‚",
            "answer": "....."
        }
    ]
}
```
- title: case disease name;
- description: case information;
- QA_pairs: a series of diagnostic questions and corresponding standard answers;



### Directory Structure
- Classification basis for major items: different types of clinical work, and special examinations [Medical postgraduate entrance examination questions] [Subject knowledge points inspection questions]

- Classification basis for small items: different medical-related occupational grades (see [Grade Catalog](catalog.md) for details) [some distinctions between Chinese and Western medicine]

- The complete topic summary is xxxx-merge.json; the directory structure is xxxx-hierarchy.json



## How to Evaluate and Submit on CMB


## CMB Evaluation Details

### CMB Test & Train & Zhenti Prompt
CMB-test Item [Sample description]()
#### Answer-only Prompt
```
{System_prompt}
<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œä¸éœ€è¦åšä»»ä½•åˆ†æå’Œè§£é‡Šï¼Œç›´æ¥è¾“å‡ºç­”æ¡ˆé€‰é¡¹ã€‚ã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼šA

[n-shot demo, n is 0 for the zero-shot case]

{System_prompt}
<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œä¸éœ€è¦åšä»»ä½•åˆ†æå’Œè§£é‡Šï¼Œç›´æ¥è¾“å‡ºç­”æ¡ˆé€‰é¡¹ã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š
```
#### Chain-of-thought Prompt

```
{System_prompt}
<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œè¯·åˆ†ææ¯ä¸ªé€‰é¡¹ï¼Œå¹¶æœ€åç»™å‡ºç­”æ¡ˆã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š.......æ‰€ä»¥ç­”æ¡ˆæ˜¯A

[n-shot demo, n is 0 for the zero-shot case]

{System_prompt}
<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸­å›½{exam_type}ä¸­{exam_class}è€ƒè¯•çš„ä¸€é“{question_type}ï¼Œè¯·åˆ†ææ¯ä¸ªé€‰é¡¹ï¼Œå¹¶æœ€åç»™å‡ºç­”æ¡ˆã€‚
{é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
...
<{Role_2}>ï¼š
```

### CMB-qa Prompt
CMB-test-qa item [Sample description]()
```
{System_prompt}
<{Role_1}>ï¼šä»¥ä¸‹æ˜¯ä¸€ä½ç—…äººçš„ç—…ä¾‹ï¼š
{description}
{QA_pairs[0]['question']}
<{Role_2}>ï¼š..........
[n-question based on the len(QA_pairs)]
```


## Licenses




## Citation

Please cite our paper if you use our dataset.
```

```
